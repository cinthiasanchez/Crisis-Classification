{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "alpha-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configuration\n",
    "\n",
    "from src import tokenizer, features, settings, classification\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aaa85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/selected/Subset_Data_Uniques.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e251d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_tokenizer = TweetTokenizer()\n",
    "column, lang = 'fixed_text_expanded', 'lan_final'\n",
    "\n",
    "\n",
    "sentence_pipeline = Pipeline([\n",
    "    ('SentenceLevelStats', features.SentenceLevelStats(column)),\n",
    "    ('FeaturesExistence', features.FeaturesExistence())\n",
    "])\n",
    "\n",
    "word_pipeline = Pipeline([\n",
    "    ('TweetTokenizer', tokenizer.TokenizerLan(obj_tokenizer, column)),\n",
    "    ('FeaturesExistence', features.WordLevelStats('tokens'))\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('FeatureUnion', FeatureUnion([\n",
    "        ('sentence_pipeline', sentence_pipeline),\n",
    "        ('word_pipeline', word_pipeline),\n",
    "        ('SentimentPolarity', features.SentimentPolarity(column, lang, False)), #last param is_translated \n",
    "        ('PartOfSpeech', features.PartOfSpeech(column, lang, False)), #last param is_translated\n",
    "    ]))\n",
    "])\n",
    "\n",
    "statistical_features = pipeline.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aerial-hayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(features.SentenceLevelStats(column).build_descriptors().keys())\n",
    "columns += ['has_{}'.format(w) for w in columns if w.startswith('_')]\n",
    "columns += list(features.WordLevelStats(column).build_descriptors().keys())\n",
    "columns[-2] = 'word_{}'.format(columns[-2])\n",
    "columns += ['polarity']\n",
    "columns += list(features.PartOfSpeech(column, lang, False).columns.keys()) #last param is_translated\n",
    "\n",
    "dataframe = pd.DataFrame(statistical_features, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acting-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "narrative-geometry",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([data, dataframe], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "advisory-young",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['uniqueness', '_url', '_user',\n",
    "                '_hashtag', '_cry', '_bless', '_fear', '_sad', '_lol', '_exclamation',\n",
    "                '_interrogate', 'nchars',\n",
    "                'word_uniqueness', 'ntokens',\n",
    "                'polarity', 'ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'DET',\n",
    "                'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM',\n",
    "                'VERB', 'X', 'I-LOC', 'I-ORG', 'I-PER']\n",
    "boolean_cols = ['has__url', 'has__user', 'has__hashtag',\n",
    "                'has__cry', 'has__bless', 'has__fear', 'has__sad', 'has__lol',\n",
    "                'has__exclamation', 'has__interrogate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "moderate-union",
   "metadata": {},
   "outputs": [],
   "source": [
    "final[numeric_cols] = final[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "final[boolean_cols] = final[boolean_cols].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313b9570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_count(number):\n",
    "    return 1 if number > 0 else 0\n",
    "\n",
    "final[\"has__I-LOC\"] = final[\"I-LOC\"].apply(binarize_count)\n",
    "final[\"has__I-ORG\"] = final[\"I-ORG\"].apply(binarize_count)\n",
    "final[\"has__I-PER\"] = final[\"I-PER\"].apply(binarize_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "expressed-causing",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('../data/selected/Subset_Data_Uniques_LF.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
